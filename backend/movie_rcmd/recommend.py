from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS, ALSModel

MONGODB_URI = 'mongodb://node1:27017,node2:27017,node3:27017,node4:27017/rcmd_db?replicaSet=mongorepl'

def ALS_recommend():
    spark = SparkSession.builder \
        .master('yarn') \
        .appName('Movie Recommendation') \
        .config('spark.mongodb.input.uri', MONGODB_URI) \
        .config('spark.mongodb.output.uri', MONGODB_URI) \
        .config('spark.yarn.archive', 'hdfs:///home/spark_jars.zip') \
        .getOrCreate()
    # spark = SparkSession.builder\
    #     .appName('Movie Recommendation') \
    #     .config('spark.mongodb.input.uri', MONGODB_URI) \
    #     .config('spark.mongodb.output.uri', MONGODB_URI) \
    #     .getOrCreate()
    sc = spark.sparkContext

    # generated by django, i.e. our user - (user, movie, rating)
    dj_ratings = spark.read.format('mongo') \
        .option('collection', 'movie_rcmd_rating') \
        .load() \
        .withColumnRenamed('user', 'userId') \
        .withColumnRenamed('movie', 'movieId')
    num_dj_ratings = dj_ratings.count()

    # movielens datasets - (userId, movieId, rating)
    ml_ratings = spark.read.csv("hdfs:///home/ratings.csv", inferSchema=True, header=True) \
        .drop('timestamp')
    ml_ratings = ml_ratings.withColumn('userId', ml_ratings.userId + num_dj_ratings)
    # ml_ratings_rdd = ml_ratings.rdd.map(lambda x: (x[0] + num_dj_ratings, x[1], x[2]))
    # ml_ratings = spark.createDataFrame(ml_ratings_rdd, ml_ratings.schema)

    all_ratings = dj_ratings.union(ml_ratings)

    als = ALS(maxIter=3, regParam=0.01, userCol='userId', itemCol='movieId', ratingCol='rating')
    als_model: ALSModel = als.fit(all_ratings)


    # users = spark.createDataFrame(sc.parallelize([str(i) for i in range(1, 11)]), ['userId'])
    # users = ratings.select('userId').distinct().limit(10).rdd.map(lambda x: (x[0] + 1,))
    # users = spark.createDataFrame(users, ['userId'])
    recommendation_rdd = als_model.recommendForUserSubset(dj_ratings, 20).rdd \
        .flatMap(lambda row: [(row[0], movie_id, weight) for movie_id, weight in row[1]])

    result = spark.createDataFrame(recommendation_rdd, ['user', 'movie', 'rating'])
    result.write.format('mongo').mode('overwrite') \
        .option('collection', 'movie_rcmd_movie_rcmd') \
        .save()

    # print('===================================== started!')

    # virtual_ratings_rdd = spark.read.csv("hdfs:///home/ratings.csv", header=True).rdd
    # virtual_ratings_rdd.saveAsTextFile('hdfs:///home/virtual_ratings')

    # print('===================================== hdfs ok!')

    # true_ratings_df = spark.read.format('mongo').load()
    # true_ratings_df.write.format('mongo').mode('overwrite').save()

    # print('===================================== mongo ok!')

    spark.stop()

if __name__ == '__main__':
    ALS_recommend()
